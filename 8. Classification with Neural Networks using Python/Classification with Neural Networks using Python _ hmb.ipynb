{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ef9720",
   "metadata": {},
   "source": [
    "Classification with Neural Networks using Python\n",
    "Classification is the task of categorizing the known classes based on their features. In most classification problems, machine learning algorithms will do the job, but while classifying a large dataset of images, you will need to use a neural network. If you have never trained a neural network and want to learn how neural networks work, you can learn everything about a neural network from here.\n",
    "\n",
    "Now let’s come back to classification with neural networks. In this section, I will take you through the task of image classification with neural network using Python. Here, I will be using the famous MNIST fashion dataset, which contains 70,000 clothing fashion images. Here our task is to train an image classification model with neural networks.\n",
    "\n",
    "I will start this task by importing the necessary Python libraries and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32b77ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fashion = keras.datasets.fashion_mnist\n",
    "(xtrain, ytrain), (xtest, ytest) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55a0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label :  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a706adcf0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgIndex = 9\n",
    "image = xtrain[imgIndex]\n",
    "print(\"Image Label : \", ytrain[imgIndex])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a16682e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Now let’s have a look at the shape of both the training and test data:\n",
    "\n",
    "\n",
    "print(xtrain.shape)\n",
    "\n",
    "print(xtest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcc47c",
   "metadata": {},
   "source": [
    "# Building a Neural Network Architecture\n",
    "### Now I will build a neural network architecture with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd34616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation= \"relu\"),\n",
    "    keras.layers.Dense(100,activation= \"relu\"),\n",
    "    keras.layers.Dense(10,activation= \"relu\"),    \n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ddd561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid , xtrain = xtrain[:5000]/255.0,xtrain[5000:]/255.0\n",
    "\n",
    "yvalid , ytrain = ytrain[:5000], ytrain[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9021ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.5460 - accuracy: 0.1042 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 8.2255 - accuracy: 0.1002 - val_loss: 8.3873 - val_accuracy: 0.0976\n"
     ]
    }
   ],
   "source": [
    "# Training a Classification Model with Neural Networks\n",
    "# Now here’s how we can train a neural network for the task of image classification:\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",optimizer = \"sgd\",metrics =[\"accuracy\"])\n",
    "history = model.fit(xtrain, ytrain, epochs = 30,\n",
    "                   validation_data = (xvalid, yvalid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07cc44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[ 2383.7275     0.         0.      4211.0474  5238.518      0.\n",
      "      0.      1342.3668  2399.8079  2076.7097]\n",
      " [ 6298.4795     0.         0.     12056.842  14273.259      0.\n",
      "      0.      3716.6414  5395.6255  4643.9736]\n",
      " [ 3773.782      0.         0.      7488.8896  8715.424      0.\n",
      "      0.      2310.1091  3080.0115  2740.333 ]\n",
      " [ 2405.0325     0.         0.      4804.1406  5554.076      0.\n",
      "      0.      1518.7294  1981.5848  1771.1536]\n",
      " [ 3839.7998     0.         0.      7299.6523  8665.454      0.\n",
      "      0.      2301.451   3297.8347  2824.0513]]\n"
     ]
    }
   ],
   "source": [
    "new = xtest[:5]\n",
    "predictions = model.predict(new)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc20ad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Here is how we can look at the predicted classes:\n",
    "\n",
    "classes = np.argmax(predictions, axis=1)\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee737468",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Classification is the task of categorizing the known classes based on their features. In most classification problems, machine learning algorithms will do the job, but while classifying a large dataset of images, you will need to use a neural network. I hope you liked this article on classification with neural network using Python. Feel free to ask valuable questions in the comments section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb11d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0ae71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
