{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c22363c",
   "metadata": {},
   "source": [
    "# Language Detection with Machine Learning\n",
    "\n",
    "Language detection is a natural language processing task where we need to identify the language of a text or document. Using machine learning for language identification was a difficult task a few years ago because there was not a lot of data on languages, but with the availability of data with ease, several powerful machine learning models are already available for language identification. So, if you want to learn how to train a machine learning model for language detection, then this article is for you. In this article, I will walk you through the task of language detection with machine learning using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45443e",
   "metadata": {},
   "source": [
    "# Language Detection\n",
    "As a human, you can easily detect the languages you know. For example, I can easily identify Hindi and English, but being an Indian, it is also not possible for me to identify all Indian languages. This is where the language identification task can be used. Google Translate is one of the most popular language translators in the world which is used by so many people around the world. It also includes a machine learning model to detect languages that you can use if you don’t know which language you want to translate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b17ea6",
   "metadata": {},
   "source": [
    "The most important part of training a language detection model is data. The more data you have about every language, the more accurate your model will perform in real-time. The dataset that I am using is collected from Kaggle, which contains data about 22 popular languages and contains 1000 sentences in each of the languages, so it will be an appropriate dataset for training a language detection model with machine learning. So in the section below, I will take you through how you can train a language detection model with machine learning using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac0557",
   "metadata": {},
   "source": [
    "# Language Detection using Python\n",
    "Let’s start the task of language detection with machine learning by importing the necessary Python libraries and the dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a29fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
      "5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
      "6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
      "7  müller mox figura centralis circulorum doctoru...     Latin\n",
      "8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
      "9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d16401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let’s have a look at whether this dataset contains any null values or not:\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a874cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "Thai          1000\n",
       "Tamil         1000\n",
       "Dutch         1000\n",
       "Japanese      1000\n",
       "Turkish       1000\n",
       "Latin         1000\n",
       "Urdu          1000\n",
       "Indonesian    1000\n",
       "Portugese     1000\n",
       "French        1000\n",
       "Chinese       1000\n",
       "Korean        1000\n",
       "Hindi         1000\n",
       "Spanish       1000\n",
       "Pushto        1000\n",
       "Persian       1000\n",
       "Romanian      1000\n",
       "Russian       1000\n",
       "English       1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let’s have a look at all the languages present in this dataset:\n",
    "\n",
    "\n",
    "data[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cd408",
   "metadata": {},
   "source": [
    "\n",
    "This dataset contains 22 languages with 1000 sentences from each language. This is a very balanced dataset with no missing values, so we can say this dataset is completely ready to be used to train a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a75975",
   "metadata": {},
   "source": [
    "# Language Detection Model\n",
    "Now let’s split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "005e3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"Text\"])\n",
    "y = np.array(data[\"language\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(x)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e151b8",
   "metadata": {},
   "source": [
    "As this is a problem of multiclass classification, so I will be using the Multinomial Naïve Bayes algorithm to train the language detection model as this algorithm always performs very well on the problems based on multiclass classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c63f546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d0bcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let’s use this model to detect the language of a text by taking a user input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "576fa9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tamil']\n"
     ]
    }
   ],
   "source": [
    "# user = input(\"Enter a text : \")\n",
    "user = ('தமிழ்ச்சங்கத்தை')\n",
    "\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39b50fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Swedish']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "user = ('今すぐバスを降')\n",
    "\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f623d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad22051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40659dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51c90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2188187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
